# NeurIPS-2024-LLM-Papers
Accepted papers related to LLM in NeurIPS 2024

| Title |
| --- |
| IDGen: Item Discrimination Induced Prompt Generation for LLM Evaluation |
| Mesa-Extrapolation: A Weave Position Encoding Method for Enhanced Extrapolation in LLMs |
| GTBench: Uncovering the Strategic Reasoning Capabilities of LLMs via Game-Theoretic Evaluations |
| Alignment at Pre-training! Towards Native Alignment for Arabic LLMs |
| Automated Multi-level Preference for MLLMs |
| LLM-ESR: Large Language Models Enhancement for Long-tailed Sequential Recommendation |
| Efficient Contextual LLM Cascades through Budget-Constrained Policy Learning |
| InfLLM: Training-Free Long-Context Extrapolation for LLMs with an Efficient Context Memory |
| Enhancing Multiple Dimensions of Trustworthiness in LLMs via Sparse Activation Control |
| MoGU: A Framework for Enhancing Safety of Open-Sourced LLMs While Preserving Their Usability |
| Tree of Attacks: Jailbreaking Black-Box LLMs Automatically |
| SpecExec: Massively Parallel Speculative Decoding For Interactive LLM Inference on Consumer Devices |
| Mixture of In-Context Experts Enhance LLMs' Long Context Awareness |
| Exploiting LLM Quantization |
| LLM Circuit Analyses Are Consistent Across Training and Scale |
| Boosting Text-to-Video Generative Model with MLLMs Feedback |
| Large Language Models as Urban Residents: An LLM Agent Framework for Personal Mobility Generation |
| LLM Evaluators Recognize and Favor Their Own Generations |
| Distributional Preference Alignment of LLMs via Optimal Transport |
| Truth is Universal: Robust Detection of Lies in LLMs |
| AmoebaLLM: Constructing Any-Shape Large Language Models for Efficient and Instant Deployment |
| Compute-efficient LLM Training via Online Batch Selection |
| Can LLMs Learn by Teaching? A Preliminary Study |
| Chain of Preference Optimization: Improving Chain-of-Thought Reasoning in LLMs |
| Mobility-LLM: Learning Visiting Intentions and Travel Preference from Human Mobility Data with Large Language Models |
| KVQuant: Towards 10 Million Context Length LLM Inference with KV Cache Quantization |
| LLMs as Zero-shot Graph Learners: Alignment of GNN Represetantions with LLM Token Embeddings |
| Long-form factuality in large language models |
| Cooperate or Collapse: Emergence of Sustainability in a Society of LLM Agents |
| Unleash Region Understanding in Intermediate Layers for MLLM-based Referring Expression Generation |
| LLM Dataset Inference: Detect Datasets, not Strings |
| FlowLLM: Flow Matching for Material Generation with Learned Base Distributions |
| When LLM Meets DRL: Advancing Jailbreaking Efficiency via DRL-guided Search |
| SlowFocus: Enhancing Fine-grained Temporal Understanding in Video LLM |
| Stacking Your Transformers: A Closer Look at Model Growth for Efficient LLM Pre-Training |
| Be like a Goldfish, Don't Memorize! Mitigating Memorization in Generative LLMs |
| MDAgents: An Adaptive Collaboration of LLMs for Medical Decision Making |
| QuanTA: Efficient High-Rank Fine-Tuning of LLMs with Quantum-Informed Tensor Adaptation |
| Aligning LLM Agents by Learning Latent Preference from User Edits |
| IDGen: Item Discrimination Induced Prompt Generation for LLM Evaluation |
| Is Programming by Example solved by LLMs? |
| LLM-ESR: Large Language Models Enhancement for Long-tailed Sequential Recommendation |
| Keeping LLMs Aligned After Fine-tuning: The Crucial Role of Prompt Templates |
| Prompting LLMs for Social Relation Reasoning via Greedy Segment Optimization |
| MediQ: Question-Asking LLMs for Adaptive and Reliable Medical Reasoning |
| StrategyLLM: Large Language Models as Strategy Generators, Executors, Optimizers, and Evaluators for Problem Solving |
| LLM-AutoDA: Large Language Model-Driven Automatic Data Augmentation for Long-tailed Problems |
| Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs |
| AGILE: A Novel Framework of LLM Agent |
| GenArtist: Multimodal LLM as an Agent for Unified Image Generation and Editing |
| Web-Scale Visual Entity Recognition: An LLM-Driven Data Approach |
| Ad Auctions for LLMs via Retrieval Augmented Generation |
| D-LLM: A Token Adaptive Computing Resource Allocation Strategy for Large Language Models |
| LLM-based Skill Diffusion for Zero-shot Policy Adaptation |
| GraphVis: Boosting LLMs with Visual Knowledge Graph Integration |
| CuMo: Scaling Multimodal LLM with Co-Upcycled Mixture-of-Experts |
| MoGU: A Framework for Enhancing Safety of Open-Sourced LLMs While Preserving Their Usability |
| The AlCHEmist: Automated Labeling 500x CHEaper than LLM Data Annotators |
| LLMDFA: Analyzing Dataflow in Code with Large Language Models |
| Mixture of In-Context Experts Enhance LLMs' Long Context Awareness |
| Tree of Attacks: Jailbreaking Black-Box LLMs Automatically |
| RankRAG: Unifying Retrieval-Augmented Generation and Context Ranking in LLMs |
| Optimized Feature Generation for Tabular Data via LLMs with Decision Tree Reasoning |
| Richelieu: Self-Evolving LLM-Based Agents for AI Diplomacy |
| Implicit Multimodal Alignment: On the Generalization of Frozen LLMs to Multimodal Inputs |
| ReST-MCTS*: LLM Self-Training via Process Reward Guided Tree Search |
| Connecting the Dots: LLMs can Infer and Verbalize Latent Structure from Disparate Training Data |
| EAI: Emotional Decision-Making of LLMs in Strategic Games and Ethical Dilemmas |
| Efficient Adversarial Training in LLMs with Continuous Attacks |
| Improved Generation of Adversarial Examples Against Safety-aligned LLMs |
| HYSYNTH: Context-Free LLM Approximation for Guiding Program Synthesis |
| MixEval: Fast and Dynamic Human Preference Approximation with LLM Benchmark Mixtures |
